# Binocular stereo
There are three python files in this part.

## calibrate_binocular_camera.py
This file is implemented to calibrate the stereo system consisting of two cameras. The calibration result contains the intrinsic matrix and distortion coefficients of both cameras ,and the rotation matrix and translation matrix between two cameras.

There is one function in this file.

- ***calibrate_each_camera(input_dir1, input_dir2, chosen_image = 1) -> rms, cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, R, T, E, F, image_size***

In this function, *input_dir1* denotes the directory containing the images generated by the left camera and *input_dir2* denotes the directory containing the images generated by the right camera. Then I use **cv2.findChessboardCorners()** to detect the corners of chessboards in each pair of images, which depict the same calibration plate. Then just like what we do in single camera calibration, **cv2.cornerSubPix()** is used to locate those corners more precisely. 

Besides, the 3-D object point coordinates, which are corresponding to those corners, are also generated for further calibration.

Obtaining the 3-D points coordinates and 2-D pixel coordinates of both left-view and right-view images, **cv2.stereoCalibrate()** is used to calibrate the stereo system. The necessary parameters are obtained by this function. Notice that, the parameter 'flag' of **cv2.stereoCalibrate()** is supposed to be some particular value instead of 'None'. Because, in my experiment, the output would be wrong if the value is 'None'.

Then the parameters obtained above and the image_size would be returned as the calibration results.

given parameters:
    
    1. input_dir1: The directory contains the left-view images.
    2. input_dir2: The directory contains the right-view images.
    3. chosen_image: The chosen_image selected to be shown to demonstrate the rectification.

return parameters:

    1. rms: The root-mean-square error of the calibration.
    2. cameraMatrix1: The intrinsic matrix of the left camera.
    3. distCoeffs1: The distortion parameters of the left camera.
    4. cameraMatrix2: The intrinsic matrix of the right camera.
    5. distCoeffs2: The distortion parameters of the right camera.
    6. R: The rotation matrix between two cameras.
    7. T: The translation matrix between two cameras.
    8. E: The essential matrix of this stereo system.
    9. F: The fundamental matrix of this stereo system.
    10. image_size: The image size of images.

## rectify.py
This file is implemented to rectify the non-parallel optical axis camera to parallel optical axis camera, which could lead to convenience to estimate the depth of one point. The prior procedure of this rectification process is the calibration, so the calibration implemented above is called at first.

Then two functions in this files are called.
- ***get_rectify_parameter(cameraMatrix1, distCoeffs1, cameraMatrix2, distCoeffs2, image_size, R, T) -> R1, R2, P1, P2, Q***

In this function, I simply use the calibration parameters of stereo system to calculate the rectification parameters with OpenCV API. The function **cv2.stereoRectify()** is called. The calibration parameters are passed to this function and the return parameters are the rectification result.

given parameters:

    1. cameraMatrix1: The intrinsic matrix of the left camera.
    2. distCoeffs1: The distortion coefficients of the left camera.
    3. cameraMatrix2: The intrinsic matrix of the right camera.
    4. distCoeffs2: The distortion coefficients of the right camera.
    5. image_size: The image size.
    6. R: The rotation matrix between two cameras.
    7. T: The translation matrix between two cameras.

return parameters:

    1. R1: The rotation matrix between the unrectified plane and rectified plane of the left camera.
    2. R2: The rotation matrix between the unrectified plane and rectified plane of the right camera.
    3. P1: The new projective matrix of the left camera.
    4. P2: The new projective matrix of the right camera.
    5. Q: The disparity-to-depth mapping matrix.

- ***rectify_image(org_image, cameraMatrix, distCoeffs, R, P, image_size) -> rectify_image***

This function, an unrectified and undistorted image could be rectified with the given parameters.

At first, **cv2.initUndistortRectifyMap()** is called by passing the intrinsic matrix, distortion coefficients, rotation matrix between the unrectified plane and rectified plane, the rectified projective matrix and the image size as parameters of particular camera to this function. Then we could obtain two maps, which represent for the undistortion map and rectification map used in the further procedure. Then **cv2.remap()** is called to rectify the original image with the two maps get above.

given parameters:

    1. org_image: An unrectified and undistorted image taken by particular camera.
    2. cameraMatrix1: The intrinsic matrix of particular camera.
    3. distCoeffs1: The distortion coefficients of particular camera.
    4. R: The rotation matrix between the unrectified plane and rectified plane
    5. P: The rectified projective matrix.
    6. image_size: The size of unrectified.

return parameters:

    1. The rectified image.

In this file, I rectify the stereo system and show the rectification result by comparing the rectified and unrectified images taken by left camera and right camera.

## estimate_baseline.py
In this file, the baseline of a rectified stereo system is estimated. 

At first, **calibrate_each_camera()** in *calibrate_binocular_camera.py* and **get_rectify_parameter()** in *rectify.py* are called to obtain corresponding parameters. Then, the rectified projective matrices of left and right camera are used to calculate the rectified optical centers of two cameras. And the baseline is calculate based on the two canters.
    
